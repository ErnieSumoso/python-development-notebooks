{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cf9807-9ec7-4f25-b60e-4fa9fd0317ba",
   "metadata": {},
   "source": [
    "#### Author: Ernie Sumoso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6310567-d9d8-4963-a160-e8da718c7a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "1-Find the cosine similarity between two given documents\n",
    "\n",
    "Input:\n",
    "\n",
    "text1='Taj Mahal is a tourist place in India'\n",
    "\n",
    "text2='Great Wall of China is a tourist place in china'\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "[[1.         0.45584231]\n",
    "\n",
    " [0.45584231 1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40a3ef4-2ec9-415f-a846-24bfb2adb5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.30069751],\n",
       "       [0.30069751, 1.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_cosine_sim_between_2_docs(doc1, doc2):\n",
    "    docs = [doc1, doc2]\n",
    "    v = TfidfVectorizer()\n",
    "    tfidf = v.fit_transform(docs)\n",
    "    pairwise_similarity = tfidf * tfidf.T\n",
    "    return pairwise_similarity.A\n",
    "\n",
    "text1='Taj Mahal is a tourist place in India'\n",
    "text2='Great Wall of China is a tourist place in china'\n",
    "get_cosine_sim_between_2_docs(text1, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5127be0-d738-49ef-8208-aa22aaece687",
   "metadata": {},
   "source": [
    "2-Compute the soft cosine similarity of the given documents\n",
    "\n",
    "Hint: Soft Cosine Similarity\n",
    "\n",
    "Input :\n",
    "\n",
    "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid. \"\n",
    "\n",
    "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\n",
    "\n",
    "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\n",
    "\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
    "\n",
    "doc_election = \"President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\n",
    "\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\"\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "0.5842470477718544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc65e59f-e676-4446-9c98-5123be9ac4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid.\"\n",
    "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\n",
    "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
    "doc_election = \"President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89d97c9-a542-41a1-805b-8cb625dad6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39530021 0.36658059 0.36504666 0.56948246 0.59257285 0.55709011]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4743454773391967"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_soft_cosine_similarity(docs):\n",
    "    v = TfidfVectorizer(stop_words='english')\n",
    "    matrix = v.fit_transform(docs)\n",
    "    concept_vector = np.mean(matrix.toarray(), axis=0)\n",
    "    soft_cosine_sim = np.dot(matrix.toarray(), concept_vector) / (np.linalg.norm(matrix.toarray(), axis=1) * np.linalg.norm(concept_vector))\n",
    "    print(soft_cosine_sim)\n",
    "    return np.mean(soft_cosine_sim)\n",
    "\n",
    "docs = [doc_soup, doc_noodles, doc_dosa, doc_trump, doc_election, doc_putin]\n",
    "get_soft_cosine_similarity(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae387e96-a429-49ec-93cc-cd8080a03630",
   "metadata": {},
   "source": [
    "3- How to create bigrams using Gensim’s Phraser ?\n",
    "\n",
    "Q. Create bigrams from the given texts using Gensim library’s Phrases\n",
    "\n",
    "Input :\n",
    "\n",
    "documents = [\"the mayor of new york was there\", \"new york mayor was present\"]\n",
    "\n",
    "Desired Output:\n",
    "\n",
    " ['the', 'mayor', 'of', 'new york', 'was', 'there']\n",
    " \n",
    "['new york', 'mayor', 'was', 'present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e9c8191-144f-4ce2-a8bf-93339972f6f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'mayor', 'of', 'new york', 'was', 'there']\n",
      "['new york', 'mayor', 'was', 'present']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "def get_bigrams_from_gensim_phraser(docs):\n",
    "    tokenized_docs = [word_tokenize(doc) for doc in docs]\n",
    "    bigram = Phrases(tokenized_docs, min_count=1, threshold=2, delimiter=' ')\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    for doc in tokenized_docs:\n",
    "        tokens_ = bigram_phraser[doc]\n",
    "        print(tokens_)\n",
    "        \n",
    "docs = [\"the mayor of new york was there\", \"new york mayor was present\"]\n",
    "get_bigrams_from_gensim_phraser(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09776628-2b37-47e9-9478-2809d13344ae",
   "metadata": {},
   "source": [
    "4- How to create bigrams, trigrams using ngrams ?\n",
    "\n",
    "Extract all bigrams , trigrams using ngrams of nltk library\n",
    "\n",
    "Input\n",
    "\n",
    "Sentences=\"Machine learning is a neccessary field in today's world. Data science can do wonders . Natural Language Processing is how machines understand text \"\n",
    "\n",
    "Desired Output:\n",
    "\n",
    "Bigrams are [('machine', 'learning'), ('learning', 'is'), ('is', 'a'), ('a', 'neccessary'), ('neccessary', 'field'), ('field', 'in'), ('in', \"today's\"), (\"today's\", 'world.'), ('world.', 'data'), ('data', 'science'), ('science', 'can'), ('can', 'do'), ('do', 'wonders'), ('wonders', '.'), ('.', 'natural'), ('natural', 'language'), ('language', 'processing'), ('processing', 'is'), ('is', 'how'), ('how', 'machines'), ('machines', 'understand'), ('understand', 'text')]\n",
    "\n",
    " Trigrams are [('machine', 'learning', 'is'), ('learning', 'is', 'a'), ('is', 'a', 'neccessary'), ('a', 'neccessary', 'field'), ('neccessary', 'field', 'in'), ('field', 'in', \"today's\"), ('in', \"today's\", 'world.'), (\"today's\", 'world.', 'data'), ('world.', 'data', 'science'), ('data', 'science', 'can'), ('science', 'can', 'do'), ('can', 'do', 'wonders'), ('do', 'wonders', '.'), ('wonders', '.', 'natural'), ('.', 'natural', 'language'), ('natural', 'language', 'processing'), ('language', 'processing', 'is'), ('processing', 'is', 'how'), ('is', 'how', 'machines'), ('how', 'machines', 'understand'), ('machines', 'understand', 'text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2a10a25-ebdb-4fa9-a1a4-7950bf55001b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 'natural'),\n",
       " ('a', 'neccessary'),\n",
       " ('can', 'do'),\n",
       " ('data', 'science'),\n",
       " ('do', 'wonders'),\n",
       " ('field', 'in'),\n",
       " ('how', 'machines'),\n",
       " ('in', \"today's\"),\n",
       " ('language', 'processing'),\n",
       " ('machine', 'learning'),\n",
       " ('machines', 'understand'),\n",
       " ('natural', 'language'),\n",
       " ('neccessary', 'field'),\n",
       " ('science', 'can'),\n",
       " (\"today's\", 'world.'),\n",
       " ('understand', 'text'),\n",
       " ('wonders', '.'),\n",
       " ('world.', 'data'),\n",
       " ('is', 'a'),\n",
       " ('is', 'how'),\n",
       " ('learning', 'is'),\n",
       " ('processing', 'is')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trigrams are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 'natural', 'language'),\n",
       " ('a', 'neccessary', 'field'),\n",
       " ('can', 'do', 'wonders'),\n",
       " ('data', 'science', 'can'),\n",
       " ('do', 'wonders', '.'),\n",
       " ('field', 'in', \"today's\"),\n",
       " ('how', 'machines', 'understand'),\n",
       " ('in', \"today's\", 'world.'),\n",
       " ('machines', 'understand', 'text'),\n",
       " ('natural', 'language', 'processing'),\n",
       " ('neccessary', 'field', 'in'),\n",
       " ('science', 'can', 'do'),\n",
       " (\"today's\", 'world.', 'data'),\n",
       " ('wonders', '.', 'natural'),\n",
       " ('world.', 'data', 'science'),\n",
       " ('is', 'a', 'neccessary'),\n",
       " ('is', 'how', 'machines'),\n",
       " ('language', 'processing', 'is'),\n",
       " ('learning', 'is', 'a'),\n",
       " ('machine', 'learning', 'is'),\n",
       " ('processing', 'is', 'how')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.metrics import TrigramAssocMeasures\n",
    "from nltk import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "def get_bigrams_trigrams_from_text(text, n=100):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        words += map(str.lower, nltk.WhitespaceTokenizer().tokenize(sentence))\n",
    "    \n",
    "    bcf = BigramCollocationFinder.from_words(words)\n",
    "    print(\"Bigrams are:\")\n",
    "    display(bcf.nbest(BigramAssocMeasures.likelihood_ratio, n))\n",
    "\n",
    "    tcf = TrigramCollocationFinder.from_words(words)\n",
    "    print(\"\\nTrigrams are:\")\n",
    "    display(tcf.nbest(TrigramAssocMeasures.likelihood_ratio, n))\n",
    "\n",
    "text = \"Machine learning is a neccessary field in today's world. Data science can do wonders . Natural Language Processing is how machines understand text \"\n",
    "get_bigrams_trigrams_from_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
